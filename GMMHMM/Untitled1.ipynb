{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Algorithms for spectral clustering\"\"\"\n",
    "\n",
    "# Author: Gael Varoquaux gael.varoquaux@normalesup.org\n",
    "#         Brian Cheung\n",
    "#         Wei LI <kuantkid@gmail.com>\n",
    "# License: BSD 3 clause\n",
    "import warnings\n",
    "import numpy as n \n",
    "from sklearn.base import BaseEstimator, ClusterMixin\n",
    "from sklearn.utils import check_random_state, as_float_array\n",
    "from sklearn.utils.validation import check_array\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.manifold import spectral_embedding\n",
    "from sklearn.cluster.k_means_ import k_means\n",
    "\n",
    "\n",
    "def discretize(vectors, copy=True, max_svd_restarts=30, n_iter_max=20,\n",
    "               random_state=None):\n",
    "    \"\"\"Search for a partition matrix (clustering) which is closest to the\n",
    "    eigenvector embedding.\n",
    "    Parameters\n",
    "    ----------\n",
    "    vectors : array-like, shape: (n_samples, n_clusters)\n",
    "        The embedding space of the samples.\n",
    "    copy : boolean, optional, default: True\n",
    "        Whether to copy vectors, or perform in-place normalization.\n",
    "    max_svd_restarts : int, optional, default: 30\n",
    "        Maximum number of attempts to restart SVD if convergence fails\n",
    "    n_iter_max : int, optional, default: 30\n",
    "        Maximum number of iterations to attempt in rotation and partition\n",
    "        matrix search if machine precision convergence is not reached\n",
    "    random_state : int, RandomState instance or None (default)\n",
    "        Determines random number generation for rotation matrix initialization.\n",
    "        Use an int to make the randomness deterministic.\n",
    "        See :term:`Glossary <random_state>`.\n",
    "    Returns\n",
    "    -------\n",
    "    labels : array of integers, shape: n_samples\n",
    "        The labels of the clusters.\n",
    "    References\n",
    "    ----------\n",
    "    - Multiclass spectral clustering, 2003\n",
    "      Stella X. Yu, Jianbo Shi\n",
    "      https://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf\n",
    "    Notes\n",
    "    -----\n",
    "    The eigenvector embedding is used to iteratively search for the\n",
    "    closest discrete partition.  First, the eigenvector embedding is\n",
    "    normalized to the space of partition matrices. An optimal discrete\n",
    "    partition matrix closest to this normalized embedding multiplied by\n",
    "    an initial rotation is calculated.  Fixing this discrete partition\n",
    "    matrix, an optimal rotation matrix is calculated.  These two\n",
    "    calculations are performed until convergence.  The discrete partition\n",
    "    matrix is returned as the clustering solution.  Used in spectral\n",
    "    clustering, this method tends to be faster and more robust to random\n",
    "    initialization than k-means.\n",
    "    \"\"\"\n",
    "\n",
    "    from scipy.sparse import csc_matrix\n",
    "    from scipy.linalg import LinAlgError\n",
    "\n",
    "    random_state = check_random_state(random_state)\n",
    "\n",
    "    vectors = as_float_array(vectors, copy=copy)\n",
    "\n",
    "    eps = np.finfo(float).eps\n",
    "    n_samples, n_components = vectors.shape\n",
    "\n",
    "    # Normalize the eigenvectors to an equal length of a vector of ones.\n",
    "    # Reorient the eigenvectors to point in the negative direction with respect\n",
    "    # to the first element.  This may have to do with constraining the\n",
    "    # eigenvectors to lie in a specific quadrant to make the discretization\n",
    "    # search easier.\n",
    "    norm_ones = np.sqrt(n_samples)\n",
    "    for i in range(vectors.shape[1]):\n",
    "        vectors[:, i] = (vectors[:, i] / np.linalg.norm(vectors[:, i])) \\\n",
    "            * norm_ones\n",
    "        if vectors[0, i] != 0:\n",
    "            vectors[:, i] = -1 * vectors[:, i] * np.sign(vectors[0, i])\n",
    "\n",
    "    # Normalize the rows of the eigenvectors.  Samples should lie on the unit\n",
    "    # hypersphere centered at the origin.  This transforms the samples in the\n",
    "    # embedding space to the space of partition matrices.\n",
    "    vectors = vectors / np.sqrt((vectors ** 2).sum(axis=1))[:, np.newaxis]\n",
    "\n",
    "    svd_restarts = 0\n",
    "    has_converged = False\n",
    "\n",
    "    # If there is an exception we try to randomize and rerun SVD again\n",
    "    # do this max_svd_restarts times.\n",
    "    while (svd_restarts < max_svd_restarts) and not has_converged:\n",
    "\n",
    "        # Initialize first column of rotation matrix with a row of the\n",
    "        # eigenvectors\n",
    "        rotation = np.zeros((n_components, n_components))\n",
    "        rotation[:, 0] = vectors[random_state.randint(n_samples), :].T\n",
    "\n",
    "        # To initialize the rest of the rotation matrix, find the rows\n",
    "        # of the eigenvectors that are as orthogonal to each other as\n",
    "        # possible\n",
    "        c = np.zeros(n_samples)\n",
    "        for j in range(1, n_components):\n",
    "            # Accumulate c to ensure row is as orthogonal as possible to\n",
    "            # previous picks as well as current one\n",
    "            c += np.abs(np.dot(vectors, rotation[:, j - 1]))\n",
    "            rotation[:, j] = vectors[c.argmin(), :].T\n",
    "\n",
    "        last_objective_value = 0.0\n",
    "        n_iter = 0\n",
    "\n",
    "        while not has_converged:\n",
    "            n_iter += 1\n",
    "\n",
    "            t_discrete = np.dot(vectors, rotation)\n",
    "\n",
    "            labels = t_discrete.argmax(axis=1)\n",
    "            vectors_discrete = csc_matrix(\n",
    "                (np.ones(len(labels)), (np.arange(0, n_samples), labels)),\n",
    "                shape=(n_samples, n_components))\n",
    "\n",
    "            t_svd = vectors_discrete.T * vectors\n",
    "\n",
    "            try:\n",
    "                U, S, Vh = np.linalg.svd(t_svd)\n",
    "                svd_restarts += 1\n",
    "            except LinAlgError:\n",
    "                print(\"SVD did not converge, randomizing and trying again\")\n",
    "                break\n",
    "\n",
    "            ncut_value = 2.0 * (n_samples - S.sum())\n",
    "            if ((abs(ncut_value - last_objective_value) < eps) or\n",
    "                    (n_iter > n_iter_max)):\n",
    "                has_converged = True\n",
    "            else:\n",
    "                # otherwise calculate rotation and continue\n",
    "                last_objective_value = ncut_value\n",
    "                rotation = np.dot(Vh.T, U.T)\n",
    "\n",
    "    if not has_converged:\n",
    "        raise LinAlgError('SVD did not converge')\n",
    "    return labels\n",
    "\n",
    "\n",
    "def spectral_clustering(affinity, n_clusters=8, n_components=None,\n",
    "                        eigen_solver=None, random_state=None, n_init=10,\n",
    "                        eigen_tol=0.0, assign_labels='kmeans'):\n",
    "    \"\"\"Apply clustering to a projection of the normalized Laplacian.\n",
    "    In practice Spectral Clustering is very useful when the structure of\n",
    "    the individual clusters is highly non-convex or more generally when\n",
    "    a measure of the center and spread of the cluster is not a suitable\n",
    "    description of the complete cluster. For instance, when clusters are\n",
    "    nested circles on the 2D plane.\n",
    "    If affinity is the adjacency matrix of a graph, this method can be\n",
    "    used to find normalized graph cuts.\n",
    "    Read more in the :ref:`User Guide <spectral_clustering>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    affinity : array-like or sparse matrix, shape: (n_samples, n_samples)\n",
    "        The affinity matrix describing the relationship of the samples to\n",
    "        embed. **Must be symmetric**.\n",
    "        Possible examples:\n",
    "          - adjacency matrix of a graph,\n",
    "          - heat kernel of the pairwise distance matrix of the samples,\n",
    "          - symmetric k-nearest neighbours connectivity matrix of the samples.\n",
    "    n_clusters : integer, optional\n",
    "        Number of clusters to extract.\n",
    "    n_components : integer, optional, default is n_clusters\n",
    "        Number of eigen vectors to use for the spectral embedding\n",
    "    eigen_solver : {None, 'arpack', 'lobpcg', or 'amg'}\n",
    "        The eigenvalue decomposition strategy to use. AMG requires pyamg\n",
    "        to be installed. It can be faster on very large, sparse problems,\n",
    "        but may also lead to instabilities\n",
    "    random_state : int, RandomState instance or None (default)\n",
    "        A pseudo random number generator used for the initialization of the\n",
    "        lobpcg eigen vectors decomposition when eigen_solver == 'amg' and by\n",
    "        the K-Means initialization. Use an int to make the randomness\n",
    "        deterministic.\n",
    "        See :term:`Glossary <random_state>`.\n",
    "    n_init : int, optional, default: 10\n",
    "        Number of time the k-means algorithm will be run with different\n",
    "        centroid seeds. The final results will be the best output of\n",
    "        n_init consecutive runs in terms of inertia.\n",
    "    eigen_tol : float, optional, default: 0.0\n",
    "        Stopping criterion for eigendecomposition of the Laplacian matrix\n",
    "        when using arpack eigen_solver.\n",
    "    assign_labels : {'kmeans', 'discretize'}, default: 'kmeans'\n",
    "        The strategy to use to assign labels in the embedding\n",
    "        space.  There are two ways to assign labels after the laplacian\n",
    "        embedding.  k-means can be applied and is a popular choice. But it can\n",
    "        also be sensitive to initialization. Discretization is another\n",
    "        approach which is less sensitive to random initialization. See\n",
    "        the 'Multiclass spectral clustering' paper referenced below for\n",
    "        more details on the discretization approach.\n",
    "    Returns\n",
    "    -------\n",
    "    labels : array of integers, shape: n_samples\n",
    "        The labels of the clusters.\n",
    "    References\n",
    "    ----------\n",
    "    - Normalized cuts and image segmentation, 2000\n",
    "      Jianbo Shi, Jitendra Malik\n",
    "      http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324\n",
    "    - A Tutorial on Spectral Clustering, 2007\n",
    "      Ulrike von Luxburg\n",
    "      http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.165.9323\n",
    "    - Multiclass spectral clustering, 2003\n",
    "      Stella X. Yu, Jianbo Shi\n",
    "      https://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf\n",
    "    Notes\n",
    "    -----\n",
    "    The graph should contain only one connect component, elsewhere\n",
    "    the results make little sense.\n",
    "    This algorithm solves the normalized cut for k=2: it is a\n",
    "    normalized spectral clustering.\n",
    "    \"\"\"\n",
    "    if assign_labels not in ('kmeans', 'discretize'):\n",
    "        raise ValueError(\"The 'assign_labels' parameter should be \"\n",
    "                         \"'kmeans' or 'discretize', but '%s' was given\"\n",
    "                         % assign_labels)\n",
    "\n",
    "    random_state = check_random_state(random_state)\n",
    "    n_components = n_clusters if n_components is None else n_components\n",
    "\n",
    "    # The first eigen vector is constant only for fully connected graphs\n",
    "    # and should be kept for spectral clustering (drop_first = False)\n",
    "    # See spectral_embedding documentation.\n",
    "    maps = spectral_embedding(affinity, n_components=n_components,\n",
    "                              eigen_solver=eigen_solver,\n",
    "                              random_state=random_state,\n",
    "                              eigen_tol=eigen_tol, drop_first=False)\n",
    "\n",
    "    if assign_labels == 'kmeans':\n",
    "        _, labels, _ = k_means(maps, n_clusters, random_state=random_state,\n",
    "                               n_init=n_init)\n",
    "    else:\n",
    "        labels = discretize(maps, random_state=random_state)\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "class SpectralClustering(BaseEstimator, ClusterMixin):\n",
    "    \"\"\"Apply clustering to a projection of the normalized Laplacian.\n",
    "    In practice Spectral Clustering is very useful when the structure of\n",
    "    the individual clusters is highly non-convex or more generally when\n",
    "    a measure of the center and spread of the cluster is not a suitable\n",
    "    description of the complete cluster. For instance when clusters are\n",
    "    nested circles on the 2D plane.\n",
    "    If affinity is the adjacency matrix of a graph, this method can be\n",
    "    used to find normalized graph cuts.\n",
    "    When calling ``fit``, an affinity matrix is constructed using either\n",
    "    kernel function such the Gaussian (aka RBF) kernel of the euclidean\n",
    "    distanced ``d(X, X)``::\n",
    "            np.exp(-gamma * d(X,X) ** 2)\n",
    "    or a k-nearest neighbors connectivity matrix.\n",
    "    Alternatively, using ``precomputed``, a user-provided affinity\n",
    "    matrix can be used.\n",
    "    Read more in the :ref:`User Guide <spectral_clustering>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_clusters : integer, optional\n",
    "        The dimension of the projection subspace.\n",
    "    eigen_solver : {None, 'arpack', 'lobpcg', or 'amg'}\n",
    "        The eigenvalue decomposition strategy to use. AMG requires pyamg\n",
    "        to be installed. It can be faster on very large, sparse problems,\n",
    "        but may also lead to instabilities.\n",
    "    random_state : int, RandomState instance or None (default)\n",
    "        A pseudo random number generator used for the initialization of the\n",
    "        lobpcg eigen vectors decomposition when ``eigen_solver='amg'`` and by\n",
    "        the K-Means initialization. Use an int to make the randomness\n",
    "        deterministic.\n",
    "        See :term:`Glossary <random_state>`.\n",
    "    n_init : int, optional, default: 10\n",
    "        Number of time the k-means algorithm will be run with different\n",
    "        centroid seeds. The final results will be the best output of\n",
    "        n_init consecutive runs in terms of inertia.\n",
    "    gamma : float, default=1.0\n",
    "        Kernel coefficient for rbf, poly, sigmoid, laplacian and chi2 kernels.\n",
    "        Ignored for ``affinity='nearest_neighbors'``.\n",
    "    affinity : string, array-like or callable, default 'rbf'\n",
    "        If a string, this may be one of 'nearest_neighbors', 'precomputed',\n",
    "        'rbf' or one of the kernels supported by\n",
    "        `sklearn.metrics.pairwise_kernels`.\n",
    "        Only kernels that produce similarity scores (non-negative values that\n",
    "        increase with similarity) should be used. This property is not checked\n",
    "        by the clustering algorithm.\n",
    "    n_neighbors : integer\n",
    "        Number of neighbors to use when constructing the affinity matrix using\n",
    "        the nearest neighbors method. Ignored for ``affinity='rbf'``.\n",
    "    eigen_tol : float, optional, default: 0.0\n",
    "        Stopping criterion for eigendecomposition of the Laplacian matrix\n",
    "        when ``eigen_solver='arpack'``.\n",
    "    assign_labels : {'kmeans', 'discretize'}, default: 'kmeans'\n",
    "        The strategy to use to assign labels in the embedding\n",
    "        space. There are two ways to assign labels after the laplacian\n",
    "        embedding. k-means can be applied and is a popular choice. But it can\n",
    "        also be sensitive to initialization. Discretization is another approach\n",
    "        which is less sensitive to random initialization.\n",
    "    degree : float, default=3\n",
    "        Degree of the polynomial kernel. Ignored by other kernels.\n",
    "    coef0 : float, default=1\n",
    "        Zero coefficient for polynomial and sigmoid kernels.\n",
    "        Ignored by other kernels.\n",
    "    kernel_params : dictionary of string to any, optional\n",
    "        Parameters (keyword arguments) and values for kernel passed as\n",
    "        callable object. Ignored by other kernels.\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        The number of parallel jobs to run.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "    Attributes\n",
    "    ----------\n",
    "    affinity_matrix_ : array-like, shape (n_samples, n_samples)\n",
    "        Affinity matrix used for clustering. Available only if after calling\n",
    "        ``fit``.\n",
    "    labels_ :\n",
    "        Labels of each point\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.cluster import SpectralClustering\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1, 1], [2, 1], [1, 0],\n",
    "    ...               [4, 7], [3, 5], [3, 6]])\n",
    "    >>> clustering = SpectralClustering(n_clusters=2,\n",
    "    ...         assign_labels=\"discretize\",\n",
    "    ...         random_state=0).fit(X)\n",
    "    >>> clustering.labels_\n",
    "    array([1, 1, 1, 0, 0, 0])\n",
    "    >>> clustering # doctest: +NORMALIZE_WHITESPACE\n",
    "    SpectralClustering(affinity='rbf', assign_labels='discretize', coef0=1,\n",
    "              degree=3, eigen_solver=None, eigen_tol=0.0, gamma=1.0,\n",
    "              kernel_params=None, n_clusters=2, n_init=10, n_jobs=None,\n",
    "              n_neighbors=10, random_state=0)\n",
    "    Notes\n",
    "    -----\n",
    "    If you have an affinity matrix, such as a distance matrix,\n",
    "    for which 0 means identical elements, and high values means\n",
    "    very dissimilar elements, it can be transformed in a\n",
    "    similarity matrix that is well suited for the algorithm by\n",
    "    applying the Gaussian (RBF, heat) kernel::\n",
    "        np.exp(- dist_matrix ** 2 / (2. * delta ** 2))\n",
    "    Where ``delta`` is a free parameter representing the width of the Gaussian\n",
    "    kernel.\n",
    "    Another alternative is to take a symmetric version of the k\n",
    "    nearest neighbors connectivity matrix of the points.\n",
    "    If the pyamg package is installed, it is used: this greatly\n",
    "    speeds up computation.\n",
    "    References\n",
    "    ----------\n",
    "    - Normalized cuts and image segmentation, 2000\n",
    "      Jianbo Shi, Jitendra Malik\n",
    "      http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324\n",
    "    - A Tutorial on Spectral Clustering, 2007\n",
    "      Ulrike von Luxburg\n",
    "      http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.165.9323\n",
    "    - Multiclass spectral clustering, 2003\n",
    "      Stella X. Yu, Jianbo Shi\n",
    "      https://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters=8, eigen_solver=None, random_state=None,\n",
    "                 n_init=10, gamma=1., affinity='rbf', n_neighbors=10,\n",
    "                 eigen_tol=0.0, assign_labels='kmeans', degree=3, coef0=1,\n",
    "                 kernel_params=None, n_jobs=None):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.eigen_solver = eigen_solver\n",
    "        self.random_state = random_state\n",
    "        self.n_init = n_init\n",
    "        self.gamma = gamma\n",
    "        self.affinity = affinity\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.eigen_tol = eigen_tol\n",
    "        self.assign_labels = assign_labels\n",
    "        self.degree = degree\n",
    "        self.coef0 = coef0\n",
    "        self.kernel_params = kernel_params\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Creates an affinity matrix for X using the selected affinity,\n",
    "        then applies spectral clustering to this affinity matrix.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like or sparse matrix, shape (n_samples, n_features)\n",
    "            OR, if affinity==`precomputed`, a precomputed affinity\n",
    "            matrix of shape (n_samples, n_samples)\n",
    "        y : Ignored\n",
    "        \"\"\"\n",
    "        X = check_array(X, accept_sparse=['csr', 'csc', 'coo'],\n",
    "                        dtype=np.float64, ensure_min_samples=2)\n",
    "        if X.shape[0] == X.shape[1] and self.affinity != \"precomputed\":\n",
    "            warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n",
    "                          \"now constructs an affinity matrix from data. To use\"\n",
    "                          \" a custom affinity matrix, \"\n",
    "                          \"set ``affinity=precomputed``.\")\n",
    "\n",
    "        if self.affinity == 'nearest_neighbors':\n",
    "            connectivity = kneighbors_graph(X, n_neighbors=self.n_neighbors,\n",
    "                                            include_self=True,\n",
    "                                            n_jobs=self.n_jobs)\n",
    "            self.affinity_matrix_ = 0.5 * (connectivity + connectivity.T)\n",
    "        elif self.affinity == 'precomputed':\n",
    "            self.affinity_matrix_ = X\n",
    "        else:\n",
    "            params = self.kernel_params\n",
    "            if params is None:\n",
    "                params = {}\n",
    "            if not callable(self.affinity):\n",
    "                params['gamma'] = self.gamma\n",
    "                params['degree'] = self.degree\n",
    "                params['coef0'] = self.coef0\n",
    "            self.affinity_matrix_ = pairwise_kernels(X, metric=self.affinity,\n",
    "                                                     filter_params=True,\n",
    "                                                     **params)\n",
    "\n",
    "        random_state = check_random_state(self.random_state)\n",
    "        self.labels_ = spectral_clustering(self.affinity_matrix_,\n",
    "                                           n_clusters=self.n_clusters,\n",
    "                                           eigen_solver=self.eigen_solver,\n",
    "                                           random_state=random_state,\n",
    "                                           n_init=self.n_init,\n",
    "                                           eigen_tol=self.eigen_tol,\n",
    "                                           assign_labels=self.assign_labels)\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def _pairwise(self):\n",
    "        return self.affinity == \"precomputed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
